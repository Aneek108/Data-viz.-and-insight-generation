# Overview of Datasets

---

## 1. Social Network Ads

### Dataset Description
`Source`: https://www.kaggle.com/datasets/nani123456789/social-network-ads

#### **Context**
An international car company wants to discover key insights from their customer database. They want to use some of the most advanced machine learning techniques to study their customers.They want to predict whether or not the customer will buy the brand new car that will be launched soon.Based on the prediction the company will advertise the product of social media.

#### **Content**
The dataset used for model building contained 400 observations of 5 variables. The data contains the following information:

* `user id` = refers to the id of the person.

* `gender` = male/female

* `age` = age of the person

* `estimated salary` = The amount of salary that the person is getting.

* `purchased` = whether the person has purchased any product or not based on his salary .

---

## 2. Bank Marketing Dataset

### Dataset Desciption:
`Source`: https://www.kaggle.com/datasets/janiobachmann/bank-marketing-dataset

#### **Context**
The dataset contains information collected during the bank's marketing campaigns. It includes various features related to bank clients, their interactions with the bank, and the outcomes of previous marketing efforts. The target variable indicates whether a client has subscribed to a term deposit account.

#### **Content**
The dataset used for model building contained 11162 observations of 17 variables. The data contains the following information:

* `Age`: Numeric feature representing the age of the bank client.

* `Job`: Categorical feature indicating the type of job the client has.

* `Marital`: Categorical feature indicating the marital status of the client.

* `Education`: Categorical feature representing the educational level of the client.

* `Default`: Categorical feature indicating whether the client has credit in default.

* `Housing`: Categorical feature indicating whether the client has a housing loan.

* `Loan`: Categorical feature indicating whether the client has a personal loan.

* `Balance`: Numeric feature representing the balance of the individual.

* `Contact`: Categorical feature indicating the communication type used to contact the client.

* `Month`: Categorical feature indicating the month of the last contact.

* `Day`: Categorical feature indicating the day of the week of the last contact.

* `Duration`: Numeric feature representing the duration of the last contact in seconds.

* `Campaign`: Numeric feature representing the number of contacts performed during the current campaign for this client.

* `Pdays`: Numeric feature representing the number of days since the client was last contacted from a previous campaign.

* `Previous`: Numeric feature representing the number of contacts performed before the current campaign for this client.

* `Poutcome`: Categorical feature representing the outcome of the previous marketing campaign.

* `deposit (Target)`: Binary feature indicating whether the client has subscribed to a term deposit.

---

## 3. Medical Insurance Cost Prediction

### Dataset Description
`Source`:https://www.kaggle.com/datasets/mirichoi0218/insurance

#### **Context**
We will build a Linear regression model for Medical cost dataset. The dataset consists of age, sex, BMI(body mass index), children, smoker and region feature, which are independent and charge as a dependent feature. We will predict individual medical costs billed by health insurance.

#### **Content**
The dataset used for model building contained 1338 observations of 7 variables. The data contains the following information:

* `age`:  age of primary beneficiary

* `sex`: insurance contractor gender, female, male

* `bmi`: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height, objective      index of body weight (kg / m ^ 2) using the ratio of height to weight, ideally 18.5 to 24.9

* `children`: Number of children covered by health insurance / Number of dependents

* `smoker`: Smoking or not.

* `region`: the beneficiary's residential area in the US, northeast, southeast, southwest, northwest.

* `charges`: Individual medical costs billed by health insurance

---

## 4. Mushroom Analysis

### Dataset Description
`Source`:https://www.kaggle.com/datasets/uciml/mushroom-classification


#### **Context**
Although this dataset was originally contributed to the UCI Machine Learning repository nearly 30 years ago, mushroom hunting (otherwise known as "shrooming") is enjoying new peaks in popularity. Learn which features spell certain death and which are most palatable in this dataset of mushroom characteristics. And how certain can your model be?

#### **Content**
This dataset includes descriptions of hypothetical samples corresponding to 23 species of gilled mushrooms in the Agaricus and Lepiota Family Mushroom drawn from The Audubon Society Field Guide to North American Mushrooms (1981). Each species is identified as definitely edible, definitely poisonous, or of unknown edibility and not recommended. This latter class was combined with the poisonous one. The Guide clearly states that there is no simple rule for determining the edibility of a mushroom; no rule like "leaflets three, let it be'' for Poisonous Oak and Ivy.

* `classes`: edible=e, poisonous=p

* `cap-shape`: bell=b,conical=c,convex=x,flat=f, knobbed=k,sunken=s

* `cap-surface`: fibrous=f,grooves=g,scaly=y,smooth=s

* `cap-color`: brown=n,buff=b,cinnamon=c,gray=g,green=r,pink=p,purple=u,red=e,white=w,yellow=y

* `bruises`: bruises=t,no=f

* `odor`: almond=a,anise=l,creosote=c,fishy=y,foul=f,musty=m,none=n,pungent=p,spicy=s

* `gill-attachment`: attached=a,descending=d,free=f,notched=n

* `gill-spacing`: close=c,crowded=w,distant=d

* `gill-size`: broad=b,narrow=n

* `gill-color`: black=k,brown=n,buff=b,chocolate=h,gray=g, green=r,orange=o,pink=p,purple=u,red=e,white=w,yellow=y

* `stalk-shape`: enlarging=e,tapering=t

* `stalk-root`: bulbous=b,club=c,cup=u,equal=e,rhizomorphs=z,rooted=r,missing=?

* `stalk-surface-above-ring`: fibrous=f,scaly=y,silky=k,smooth=s

* `stalk-surface-below-ring`: fibrous=f,scaly=y,silky=k,smooth=s

* `stalk-color-above-ring`: brown=n,buff=b,cinnamon=c,gray=g,orange=o,pink=p,red=e,white=w,yellow=y

* `stalk-color-below-ring`: brown=n,buff=b,cinnamon=c,gray=g,orange=o,pink=p,red=e,white=w,yellow=y

* `veil-type`: partial=p,universal=u

* `veil-color`: brown=n,orange=o,white=w,yellow=y

* `ring-number`: none=n,one=o,two=t

* `ring-type`: cobwebby=c,evanescent=e,flaring=f,large=l,none=n,pendant=p,sheathing=s,zone=z

* `spore-print-color`: black=k,brown=n,buff=b,chocolate=h,green=r,orange=o,purple=u,white=w,yellow=y

* `population`: abundant=a,clustered=c,numerous=n,scattered=s,several=v,solitary=y

* `habitat`: grasses=g,leaves=l,meadows=m,paths=p,urban=u,waste=w,woods=d

---

## 5. Calories Burnt Prediction

### Dataset Description
`Source`: https://www.kaggle.com/datasets/fmendes/fmendesdat263xdemos

#### **Context**
In today's health-conscious society, monitoring and managing calorie expenditure is a key aspect of maintaining a healthy lifestyle. Understanding how various activities and individual factors impact calorie burn is crucial for individuals striving to achieve fitness goals. Leveraging the capabilities of data science, we aim to address this health and wellness challenge.

This project falls within the domain of Regression Machine Learning Problem. The primary objective is to develop a predictive model for calorie burnt prediction. By analyzing a combination of input features such as physical activity type, duration, intensity, and individual characteristics like age, weight, and gender, the goal is to create a model that accurately estimates the number of calories burnt during a specific activity. This predictive model can empower individuals, fitness enthusiasts, and healthcare professionals with valuable insights to optimize their calorie management and physical activity planning.

#### **Content**
There are two datasets named exercise (15000 observations and 8 variable )and calories (containing 15000 observations and 2 variable) . The data contains the following information:

* `USER-ID` - User_id od the person.

* `Gender` - Gender of the person.

* `Age` - Age of the person.

* `Height` - Height of the person.

* `Weight` - Weight of the person.

* `Duration` - Duration of the exercise performed by the person.

* `Heart_Rate` - Heart_Rate of the person.

* `Body_Temp` - Body_Temp of the person.

* `Calories` - Total calories burnt by the person.

---

## 6. # Titanic Survival Prediction

### Dataset Desciption:
`Source`: https://www.kaggle.com/datasets/yasserh/titanic-dataset/data

#### **Context**
The sinking of the Titanic is one of the most infamous shipwrecks in history.
On April 15, 1912, during her maiden voyage, the widely considered “unsinkable” RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone on board, resulting in the death of 1502 out of 2224 passengers and crew.

While there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.


#### **Content**
The dataset used for model building contained 891 observations of 12 variables. The data contains the following information:

* `Passenger ID`: Numeric feature representing the passengerID.

* `Survived`: Categorical feature indicating weather the passenger survived or not

* `Pclass`: Numerical feature representing the class of the passenger.

* `Name`: Representing the name of the passenger.

* `Sex`: Categorical feature indicating the age of the passenger.

* `Age`: Numerical feature indicating the age of the passenger.

* `SibSp`: Representing no. of siblings / spouses aboard the Titanic

* `Parch`: Representing no. of parents / children aboard the Titanic

* `Ticket`: Representing the ticket no. of the passenger.

* `Fare`: Representing the passenger fare.

* `Cabin`: Representing the cabin no. of the passenger.

* `Embarked`: Embarked implies where the passenger mounted from.

---

## 7. Parkinson Disease Detection

### Dataset Description
`Source`: https://www.kaggle.com/datasets/jainaru/parkinson-disease-detection?resource=download

#### **Context**
Parkinson’s Disease (PD) is a degenerative neurological disorder marked by decreased dopamine levels in the brain. It manifests itself through a deterioration of movement, including the presence of tremors and stiffness. There is commonly a marked effect on speech, including dysarthria (difficulty articulating sounds), hypophonia (lowered volume), and monotone (reduced pitch range). Additionally, cognitive impairments and changes in mood can occur, and risk of dementia is increased.

Traditional diagnosis of Parkinson’s Disease involves a clinician taking a neurological history of the patient and observing motor skills in various situations. Since there is no definitive laboratory test to diagnose PD, diagnosis is often difficult, particularly in the early stages when motor effects are not yet severe. Monitoring progression of the disease over time requires repeated clinic visits by the patient. An effective screening process, particularly one that doesn’t require a clinic visit, would be beneficial. Since PD patients exhibit characteristic vocal features, voice recordings are a useful and non-invasive tool for diagnosis. If machine learning algorithms could be applied to a voice recording dataset to accurately diagnosis PD, this would be an effective screening step prior to an appointment with a clinician

#### **Content**
This dataset is composed of a range of biomedical voice measurements from 31 people, 23 with Parkinson's disease (PD). Each column in the table is a particular voice measure, and each row corresponds to one of 195 voice recordings from these individuals ("name" column). The main aim of the data is to discriminate healthy people from those with PD, according to the "status" column which is set to 0 for healthy and 1 for PD. The data contains the following information:

* `name` - ASCII subject name and recording number

* `MDVP:Fo(Hz)` - Average vocal fundamental frequency

* `MDVP:Fhi(Hz)` - Maximum vocal fundamental frequency

* `MDVP:Flo(Hz)` - Minimum vocal fundamental frequency

* `MDVP:Jitter(%)`,`MDVP:Jitter(Abs)`,`MDVP:RAP`,`MDVP:PPQ`,`Jitter:DDP` - Several
measures of variation in fundamental frequency

* `MDVP:Shimmer`,`MDVP:Shimmer(dB)`,`Shimmer:APQ3`,`Shimmer:APQ5`,`MDVP:APQ`,`Shimmer:DDA` - Several measures of variation in amplitude

* `NHR`,`HNR` - Two measures of ratio of noise to tonal components in the voice
status - Health status of the subject (one) - Parkinson's, (zero) - healthy

* `RPDE`,`D2` - Two nonlinear dynamical complexity measures

* `DFA` - Signal fractal scaling exponent

* `spread1`,`spread2`,`PPE` - Three nonlinear measures of fundamental frequency variation'

---

## 8. # Credit Card Fraud Detection

### Dataset Desciption:
`Source`: https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud

#### **Context**
The dataset contains transactions made by credit cards in September 2013 by European cardholders.
This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.

It contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, … V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-sensitive learning. Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise.

Given the class imbalance ratio, we recommend measuring the accuracy using the Area Under the Precision-Recall Curve (AUPRC). Confusion matrix accuracy is not meaningful for unbalanced classification.

---

## 9.Iris Flower Classification

### Dataset Desciption:
`Source`: https://www.kaggle.com/datasets/arshid/iris-flower-dataset

#### **Context**
The Iris flower data set is a multivariate data set introduced by the British statistician and biologist Ronald Fisher in his 1936 paper The use of multiple measurements in taxonomic problems. It is sometimes called Anderson's Iris data set because Edgar Anderson collected the data to quantify the morphologic variation of Iris flowers of three related species. The data set consists of 50 samples from each of three species of Iris (Iris Setosa, Iris virginica, and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters.

This dataset became a typical test case for many statistical classification techniques in machine learning such as support vector machines

#### **Content**
The dataset used for model building contained 150 observations of 5 variables. The data contains the following information:

* `Sepal-length`: Numeric feature representing the length of the sepal.

* `Sepal-width`: Numeric feature representing the width of the sepal.

* `Petal-length`: Numerical feature representing the length of the petal.

* `Petal-width`: Numeric feature representing the width of the petal.

* `Species`: Categorical feature indicating the species of the iris flower.